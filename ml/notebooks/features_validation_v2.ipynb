{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14baefd0",
   "metadata": {},
   "source": [
    "\n",
    "# Features Validation — v2\n",
    "\n",
    "**Project:** Housing Insights & Risk Dashboard  \n",
    "**Author:** Auto-generated by ChatGPT  \n",
    "**Created:** 2025-10-10 03:05  \n",
    "\n",
    "### Purpose\n",
    "Validate engineered features prior to modeling. This notebook performs:\n",
    "- Distribution checks\n",
    "- Correlation analysis\n",
    "- Missing-value profiling\n",
    "- Time-series sanity checks\n",
    "- Auto-generated summary report\n",
    "\n",
    "> **Tip:** If you run inside your repo, save this file under: `/ml/notebooks/features_validation_v2.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CONFIG (edit if needed) ===============================================\n",
    "# Path to your .env file (loaded with python-dotenv)\n",
    "ENV_PATH = \"/mnt/data/env.txt\"  # <- change if running elsewhere\n",
    "\n",
    "# Name of your features table in Postgres\n",
    "FEATURES_TABLE = \"features\"  # e.g., \"features\" or \"public.features\"\n",
    "\n",
    "# Optional: Schema name; if empty, default search path is used\n",
    "SCHEMA = \"\"\n",
    "\n",
    "# Time column (for time-series validation). Change if your table uses a different name.\n",
    "TIME_COL = \"date\"  # e.g., \"date\" (YYYY-MM or YYYY-MM-DD) or \"period\"\n",
    "\n",
    "# City/category column (for grouping). Change to your actual column if needed.\n",
    "CITY_COL = \"city\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d94409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== IMPORTS ==============================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Plotting (matplotlib only; no seaborn, no explicit colors)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Environment loader\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "except ImportError:\n",
    "    raise ImportError(\"Please install python-dotenv: pip install python-dotenv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64969bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== LOAD ENV & CONNECT ====================================================\n",
    "# Load environment variables from ENV_PATH\n",
    "load_dotenv(ENV_PATH)\n",
    "\n",
    "# Prefer DATABASE_URL; else assemble from discrete vars\n",
    "db_url = os.getenv(\"DATABASE_URL\", \"\").strip()\n",
    "if not db_url:\n",
    "    host = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "    port = os.getenv(\"POSTGRES_PORT\", \"5432\")\n",
    "    db = os.getenv(\"POSTGRES_DB\", \"postgres\")\n",
    "    user = os.getenv(\"POSTGRES_USER\", \"postgres\")\n",
    "    pwd = os.getenv(\"POSTGRES_PASSWORD\", \"postgres\")\n",
    "    db_url = f\"postgresql+psycopg2://{user}:{pwd}@{host}:{port}/{db}\"\n",
    "\n",
    "print(\"Using DATABASE_URL =\", db_url)\n",
    "\n",
    "# Create engine (no connection attempt yet)\n",
    "engine = create_engine(db_url, future=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== LOAD FEATURES TABLE ===================================================\n",
    "# You can filter columns here if you want to limit the EDA scope.\n",
    "with engine.connect() as conn:\n",
    "    # Try schema-qualified name if SCHEMA provided\n",
    "    table_expr = f\"{SCHEMA}.{FEATURES_TABLE}\" if SCHEMA else FEATURES_TABLE\n",
    "    query = text(f\"SELECT * FROM {table_expr} LIMIT 5\")\n",
    "    try:\n",
    "        preview = pd.read_sql(query, conn)\n",
    "        print(f\"Preview of '{table_expr}' (first 5 rows):\")\n",
    "        display(preview)\n",
    "    except Exception as e:\n",
    "        print(\"Could not preview table. Check SCHEMA/FEATURES_TABLE. Error:\\n\", e)\n",
    "        raise\n",
    "\n",
    "# Load full (or sample if huge)\n",
    "SAMPLE_ROWS = None  # set to an int (e.g., 200000) if your table is large\n",
    "with engine.connect() as conn:\n",
    "    if SAMPLE_ROWS:\n",
    "        df = pd.read_sql(\n",
    "            text(f\"SELECT * FROM {table_expr} LIMIT :n\"),\n",
    "            conn,\n",
    "            params={\"n\": SAMPLE_ROWS},\n",
    "        )\n",
    "    else:\n",
    "        df = pd.read_sql(text(f\"SELECT * FROM {table_expr}\"), conn)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346944da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== BASIC INFO ============================================================\n",
    "print(\"\\nDataFrame info():\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nDescribe (numeric):\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "na_counts = df.isna().sum().sort_values(ascending=False)\n",
    "display(na_counts.to_frame(\"missing_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896489fb",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab36385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== DISTRIBUTIONS =========================================================\n",
    "# Pick a subset of numeric columns to plot (avoid too many figures)\n",
    "# Auto-detect numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# If you have a known list of feature columns, you can replace numeric_cols with it.\n",
    "# Example:\n",
    "# numeric_cols = [\"hpi\", \"rent_median\", \"price_to_rent\", \"unemployment_rate\", \"inventory\"]\n",
    "\n",
    "# Plot histograms\n",
    "MAX_PLOTS = 12\n",
    "plot_cols = numeric_cols[:MAX_PLOTS]\n",
    "print(f\"Plotting histograms for up to {MAX_PLOTS} numeric columns:\", plot_cols)\n",
    "\n",
    "for col in plot_cols:\n",
    "    plt.figure()\n",
    "    df[col].hist(bins=30)\n",
    "    plt.title(f\"Histogram — {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774a910",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CORRELATIONS ==========================================================\n",
    "if len(numeric_cols) >= 2:\n",
    "    corr = df[numeric_cols].corr(numeric_only=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(corr.values, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.index)), corr.index)\n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough numeric columns for correlation matrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a658b92",
   "metadata": {},
   "source": [
    "## Time-Series Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddde86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== TIME-SERIES CHECKS ====================================================\n",
    "# Attempt to parse TIME_COL into datetime\n",
    "if TIME_COL in df.columns:\n",
    "    ts = df.copy()\n",
    "    ts[TIME_COL] = pd.to_datetime(ts[TIME_COL], errors=\"coerce\")\n",
    "    ts = ts.dropna(subset=[TIME_COL])\n",
    "    ts = ts.sort_values(TIME_COL)\n",
    "\n",
    "    # Overall trend on a key metric (auto-pick first numeric col if you don't specify)\n",
    "    key_metric = None\n",
    "    for c in numeric_cols:\n",
    "        if c != TIME_COL:\n",
    "            key_metric = c\n",
    "            break\n",
    "\n",
    "    if key_metric:\n",
    "        # Plot overall trend (all cities combined)\n",
    "        plt.figure()\n",
    "        ts.groupby(TIME_COL)[key_metric].mean().plot()\n",
    "        plt.title(f\"Mean {key_metric} over time (all groups)\")\n",
    "        plt.xlabel(TIME_COL)\n",
    "        plt.ylabel(f\"{key_metric} (mean)\")\n",
    "        plt.show()\n",
    "\n",
    "        # Plot per-city if CITY_COL exists\n",
    "        if CITY_COL in ts.columns:\n",
    "            # pick a few top cities by row count\n",
    "            top = ts[CITY_COL].value_counts().head(5).index.tolist()\n",
    "            for c in top:\n",
    "                sub = ts[ts[CITY_COL] == c]\n",
    "                if sub.empty:\n",
    "                    continue\n",
    "                plt.figure()\n",
    "                sub.groupby(TIME_COL)[key_metric].mean().plot()\n",
    "                plt.title(f\"{key_metric} over time — {c}\")\n",
    "                plt.xlabel(TIME_COL)\n",
    "                plt.ylabel(key_metric)\n",
    "                plt.show()\n",
    "    else:\n",
    "        print(\"No numeric key metric found for time-series plot.\")\n",
    "else:\n",
    "    print(\n",
    "        f\"TIME_COL='{TIME_COL}' not found in df.columns. Set correct column name at the top.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61003dc5",
   "metadata": {},
   "source": [
    "## Quick Outlier Check (Z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc3a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== OUTLIER CHECK =========================================================\n",
    "from scipy.stats import zscore\n",
    "\n",
    "outlier_summary = {}\n",
    "for col in numeric_cols:\n",
    "    s = df[col].dropna()\n",
    "    if s.empty:\n",
    "        continue\n",
    "    z = zscore(s.to_numpy())\n",
    "    # threshold 3 as a basic heuristic\n",
    "    outliers = (np.abs(z) > 3).sum()\n",
    "    outlier_summary[col] = int(outliers)\n",
    "\n",
    "outlier_df = pd.DataFrame.from_dict(\n",
    "    outlier_summary, orient=\"index\", columns=[\"n_outliers\"]\n",
    ").sort_values(\"n_outliers\", ascending=False)\n",
    "display(outlier_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bff32a",
   "metadata": {},
   "source": [
    "## Auto-Generated Summary (Draft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34938aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== SUMMARY GENERATION ====================================================\n",
    "# This section generates a concise Markdown report based on basic stats.\n",
    "# You can re-run after changing config or applying filters above.\n",
    "\n",
    "lines = []\n",
    "lines.append(\"# Feature Validation — Auto Summary\\n\")\n",
    "\n",
    "# Basic shape\n",
    "rows, cols = df.shape\n",
    "lines.append(f\"- **Rows:** {rows:,}\")\n",
    "lines.append(f\"- **Columns:** {cols:,}\")\n",
    "\n",
    "# Missingness\n",
    "na_top = df.isna().sum().sort_values(ascending=False).head(10)\n",
    "if na_top.iloc[0] > 0:\n",
    "    lines.append(\"\\n### Missingness (Top 10)\")\n",
    "    for k, v in na_top.items():\n",
    "        if v > 0:\n",
    "            pct = (v / rows * 100.0) if rows else 0.0\n",
    "            lines.append(f\"- {k}: {v:,} ({pct:.2f}%)\")\n",
    "\n",
    "# Correlation highlights\n",
    "if \"corr\" in globals():\n",
    "    # Find the strongest pairs (upper triangle, excluding self)\n",
    "    corr_abs = corr.abs()\n",
    "    # Mask diagonal\n",
    "    np.fill_diagonal(corr_abs.values, 0.0)\n",
    "    # Find top pairs\n",
    "    pairs = []\n",
    "    cols_ = corr_abs.columns.tolist()\n",
    "    for i in range(len(cols_)):\n",
    "        for j in range(i + 1, len(cols_)):\n",
    "            pairs.append(((cols_[i], cols_[j]), corr_abs.iloc[i, j]))\n",
    "    pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_pairs = pairs[:5]\n",
    "    if top_pairs:\n",
    "        lines.append(\"\\n### Strongest Correlations (Top 5, absolute)\")\n",
    "        for (a, b), r in top_pairs:\n",
    "            lines.append(f\"- {a} ↔ {b}: {r:.3f}\")\n",
    "\n",
    "# Outliers\n",
    "if \"outlier_df\" in globals() and not outlier_df.empty:\n",
    "    worst = outlier_df.head(5)\n",
    "    lines.append(\"\\n### Columns with Most Z>3 Outliers (Top 5)\")\n",
    "    for idx, row in worst.iterrows():\n",
    "        lines.append(f\"- {idx}: {int(row['n_outliers'])}\")\n",
    "\n",
    "# Time sanity checks\n",
    "if TIME_COL in df.columns:\n",
    "    lines.append(\"\\n### Time-Series Sanity\")\n",
    "    try:\n",
    "        tmin = pd.to_datetime(df[TIME_COL], errors=\"coerce\").min()\n",
    "        tmax = pd.to_datetime(df[TIME_COL], errors=\"coerce\").max()\n",
    "        lines.append(f\"- Time range: {tmin} → {tmax}\")\n",
    "    except Exception as e:\n",
    "        lines.append(f\"- Could not parse {TIME_COL}: {e}\")\n",
    "\n",
    "# Convert to Markdown cell\n",
    "summary_md = \"\\n\".join(lines)\n",
    "print(summary_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddce6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== WRITE SUMMARY MARKDOWN CELL ===========================================\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "try:\n",
    "    display(Markdown(summary_md))\n",
    "except NameError:\n",
    "    print(\"Run the previous cell to create 'summary_md' first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e109397c",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Appendix\n",
    "\n",
    "- If your features table is very large, set `SAMPLE_ROWS` in the **Load Features Table** cell.\n",
    "- Ensure `TIME_COL` and `CITY_COL` match your schema.\n",
    "- For exporting figures, you can save with `plt.savefig(\"path.png\", dpi=150, bbox_inches=\"tight\")` after each plot.\n",
    "\n",
    "**Done.** Proceed to commit this notebook and link it in your documentation (`/docs/modeling.md`).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
